# AI Council Architecture for Huracan Observability

**Purpose**: Multi-agent AI system for analyzing trading engine performance with zero hallucination

---

## Architecture Overview

```
METRICS_JSON (Pre-Computed Aggregates)
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   COUNCIL OF ANALYST MODELS      â”‚
    â”‚  (7 models analyze in parallel)  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 1. GPT-4-Turbo    (OpenAI)       â”‚
    â”‚ 2. Claude Sonnet  (Anthropic)    â”‚
    â”‚ 3. Claude Opus    (Anthropic)    â”‚
    â”‚ 4. Gemini 1.5 Pro (Google)       â”‚
    â”‚ 5. Grok 2         (xAI)          â”‚
    â”‚ 6. Llama 3 70B    (Meta)         â”‚
    â”‚ 7. DeepSeek-R1    (DeepSeek)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    Structured Claims + Evidence
           â†“
    Number Verification Filter
           â†“
    Only Verified Claims Pass
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      JUDGE MODEL                 â”‚
    â”‚  (Claude Opus or GPT-4-Turbo)    â”‚
    â”‚                                  â”‚
    â”‚  Scores + Merges + Synthesizes   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    Final Report (Human-Readable)
```

---

## Key Principles

### 1. Zero Hallucination Guarantee
- **Only aggregated metrics** go to models (never raw logs)
- **Every number must exist** in METRICS_JSON
- **Structured claims** with metric IDs
- **Code verification** before Judge sees claims
- **Temperature 0.0-0.1** for determinism

### 2. Diverse Reasoning
- **7 different models** analyze same data
- Each has different strengths:
  - GPT-4-Turbo: Strong general reasoning
  - Claude Opus: Best at structured analysis
  - Gemini: Good at correlations
  - Grok 2: Pattern detection
  - Llama 3: Open-source baseline
  - DeepSeek: Chain-of-thought reasoning
- Judge synthesizes diverse perspectives

### 3. Factual Verification
- **Claim validation**: Every claim links to metric ID
- **Number matching**: Values must match exactly (Â±0.01%)
- **Discard invalid**: Any analyst with fake numbers is rejected
- **Judge cannot invent**: Can only merge verified claims

---

## Analyst Output Format

Each analyst produces:

```json
{
  "analyst_id": "gpt-4-turbo",
  "timestamp": "2025-11-06T14:00:00Z",
  "claims": [
    {
      "claim_id": "claim_1",
      "category": "performance",
      "statement": "Scalp mode executed 38 trades with 74% win rate",
      "evidence": {
        "metric_id": "wr_scalp_2025-11-06",
        "expected_value": 0.74,
        "actual_value": 0.74,
        "verify_link": "metrics://wr?mode=scalp&date=2025-11-06"
      },
      "confidence": 1.0
    },
    {
      "claim_id": "claim_2",
      "category": "learning",
      "statement": "Meta-label model improved from 0.68 to 0.71 AUC (+4.4%)",
      "evidence": {
        "metric_id": "model_delta_v11_v12",
        "expected_values": {"before": 0.68, "after": 0.71, "delta": 0.044},
        "verify_link": "metrics://model?from=v11&to=v12"
      },
      "confidence": 1.0
    }
  ],
  "summary": "Today scalp mode met targets (38 trades, 74% WR) while runner fell short (87% vs 90% target). The meta-label model improved by 4.4% after retraining.",
  "insights": [
    {
      "type": "warning",
      "message": "Runner WR below target",
      "recommendation": "Investigate TREND engine confidence calibration",
      "priority": "medium"
    }
  ],
  "reasoning_trace": "Analyzed win rates first, then model evolution, then gate performance..."
}
```

---

## Judge Evaluation Criteria

Judge scores each analyst on:

1. **Factual Accuracy (40%)**: All numbers match metrics exactly
2. **Coverage (20%)**: How much of the data was analyzed
3. **Specificity (15%)**: Concrete actionable insights vs vague
4. **Clarity (10%)**: Easy to understand
5. **Novelty (15%)**: Unique insights not in other analysts

Judge output:

```json
{
  "judge_id": "claude-opus",
  "timestamp": "2025-11-06T14:01:00Z",
  "analyst_scores": {
    "gpt-4-turbo": {"accuracy": 1.0, "coverage": 0.85, "specificity": 0.90, "clarity": 0.95, "novelty": 0.70, "total": 0.88},
    "claude-sonnet": {"accuracy": 1.0, "coverage": 0.90, "specificity": 0.85, "clarity": 0.90, "novelty": 0.65, "total": 0.86},
    // ... more
  },
  "synthesis": {
    "key_facts": [
      "Scalp: 38 trades, 74% WR (target met)",
      "Runner: 8 trades, 87% WR (below 90% target)",
      "Model updated: v11â†’v12, AUC +4.4%"
    ],
    "insights": [
      "Runner underperformance likely due to TREND engine miscalibration (3 analysts agree)",
      "Gates blocked 12 winning trades worth Â£18 (consider loosening meta_label threshold)"
    ],
    "recommendations": [
      {
        "priority": "high",
        "action": "Investigate TREND engine confidence scores",
        "expected_impact": "Improve runner WR by 3-5%",
        "consensus": 5  // 5 out of 7 analysts agreed
      }
    ]
  },
  "final_report": "ðŸ“Š HURACAN DAILY SUMMARY - November 6, 2025\n\nðŸŽ¯ Performance\n- Scalp: 38 trades, 74% WR [verify] âœ“ Target met\n- Runner: 8 trades, 87% WR [verify] âš ï¸ Below 90% target\n\n..."
}
```

---

## Anti-Hallucination Design

### Layer 1: Input Control
```python
# Only aggregated metrics, never raw logs
metrics_json = {
    "date": "2025-11-06",
    "overall": {"wr": 0.75, "trades": 46, "pnl_gbp": 127.0},
    "scalp": {"wr": 0.74, "trades": 38, "pnl_gbp": 45.0},
    "runner": {"wr": 0.87, "trades": 8, "pnl_gbp": 82.0},
    "model_v12": {"auc": 0.710, "ece": 0.061, "trained_at": "14:37:42"},
    "verify_links": {
        "wr_scalp": "metrics://wr?mode=scalp&date=2025-11-06",
        "model_v12": "metrics://model?id=sha256:abc123"
    }
}
```

### Layer 2: Strict Prompts
```python
ANALYST_SYSTEM_PROMPT = """You are a factual analyst for Huracan trading engine.

RULES:
1. Use ONLY numbers from METRICS_JSON
2. Every claim must reference a metric ID
3. If data is missing, say "insufficient data"
4. Never estimate, speculate, or invent numbers
5. Temperature 0.0 - be deterministic

OUTPUT FORMAT:
{
  "claims": [{"statement": "...", "evidence": {"metric_id": "...", "expected_value": X}}],
  "summary": "..."
}
"""
```

### Layer 3: Number Verification
```python
def verify_claim(claim, metrics_json):
    """Verify claim against source metrics"""
    metric_id = claim["evidence"]["metric_id"]
    expected = claim["evidence"]["expected_value"]

    # Look up actual value in metrics
    actual = get_metric_value(metrics_json, metric_id)

    # Must match exactly (within 0.01% tolerance)
    if abs(actual - expected) / actual > 0.0001:
        return False, f"Mismatch: expected {expected}, got {actual}"

    return True, "OK"

# Reject entire analyst if any claim fails
for claim in analyst_output["claims"]:
    valid, reason = verify_claim(claim, metrics_json)
    if not valid:
        reject_analyst(analyst_output, reason)
```

### Layer 4: Judge Cannot Invent
```python
JUDGE_SYSTEM_PROMPT = """You are the Judge for analyst council.

RULES:
1. You can ONLY use claims from verified analysts
2. You CANNOT add new numbers
3. You can rephrase, merge, prioritize
4. Score each analyst on accuracy, coverage, specificity, clarity, novelty
5. Synthesize a final report citing sources

DO NOT invent or estimate anything.
"""
```

---

## Implementation Architecture

### File Structure
```
observability/ai/
â”œâ”€â”€ council/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analyst.py           # Base analyst class
â”‚   â”œâ”€â”€ judge.py             # Judge model
â”‚   â”œâ”€â”€ verifier.py          # Number verification
â”‚   â”œâ”€â”€ council_manager.py   # Orchestrates council
â”‚   â””â”€â”€ schemas.py           # Claim, Evidence, Report schemas
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ gpt4.py              # OpenAI GPT-4-Turbo
â”‚   â”œâ”€â”€ claude.py            # Anthropic Claude
â”‚   â”œâ”€â”€ gemini.py            # Google Gemini
â”‚   â”œâ”€â”€ grok.py              # xAI Grok 2
â”‚   â”œâ”€â”€ llama.py             # Meta Llama 3
â”‚   â”œâ”€â”€ deepseek.py          # DeepSeek-R1
â”‚   â””â”€â”€ meta_ai.py           # Meta AI
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ analyst_prompts.py   # Per-model prompts
â”‚   â””â”€â”€ judge_prompts.py     # Judge prompts
â””â”€â”€ monitoring/
    â”œâ”€â”€ accuracy_tracker.py  # Track analyst accuracy over time
    â””â”€â”€ council_metrics.py   # Council performance metrics
```

### Council Manager
```python
class CouncilManager:
    def __init__(self):
        self.analysts = [
            GPT4Analyst(),
            ClaudeSonnetAnalyst(),
            ClaudeOpusAnalyst(),
            GeminiAnalyst(),
            GrokAnalyst(),
            LlamaAnalyst(),
            DeepSeekAnalyst()
        ]
        self.judge = ClaudeOpusJudge()
        self.verifier = NumberVerifier()
        self.accuracy_tracker = AccuracyTracker()

    async def analyze(self, metrics_json: dict) -> Report:
        """Run full council analysis"""
        # 1. All analysts analyze in parallel
        analyst_outputs = await asyncio.gather(*[
            analyst.analyze(metrics_json)
            for analyst in self.analysts
        ])

        # 2. Verify each analyst's claims
        verified_outputs = []
        for output in analyst_outputs:
            if self.verifier.verify_all_claims(output, metrics_json):
                verified_outputs.append(output)
            else:
                logger.warning(f"{output.analyst_id} rejected - invalid claims")

        # 3. Judge evaluates and synthesizes
        final_report = await self.judge.evaluate(verified_outputs, metrics_json)

        # 4. Track accuracy for adaptive weighting
        self.accuracy_tracker.record(verified_outputs, final_report)

        return final_report
```

---

## Strengths of This Design

1. **Zero Hallucination**: Multiple layers prevent invented numbers
2. **Diverse Perspectives**: 7 models = 7 different angles on data
3. **Self-Correcting**: Judge catches inconsistencies between analysts
4. **Verifiable**: Every claim traceable to source metric
5. **Robust**: If one model hallucinates, others + judge catch it
6. **Adaptable**: Track accuracy, weight models over time

---

## Weaknesses to Address

1. **Cost**: 8 API calls per summary (7 analysts + 1 judge)
   - **Mitigation**: Cache results, use smaller models for routine checks

2. **Latency**: Parallel calls help, but still ~5-10s total
   - **Mitigation**: Pre-compute metrics, run async, acceptable for daily summaries

3. **Groupthink**: Models might converge on similar insights
   - **Mitigation**: Use different prompts, encourage contrarian views

4. **Judge Bias**: Judge might favor certain analysts
   - **Mitigation**: Blind evaluation (Judge doesn't see analyst IDs initially)

5. **Prompt Drift**: Models updated, behavior changes
   - **Mitigation**: Version prompts, track accuracy over time

---

## Improvements & Extensions

### 1. Adaptive Weighting
Track historical accuracy, weight analysts dynamically:

```python
class AccuracyTracker:
    def get_weights(self) -> dict:
        """Historical accuracy â†’ weights"""
        return {
            "gpt-4-turbo": 0.18,     # 18% weight (high accuracy)
            "claude-opus": 0.16,
            "gemini": 0.15,
            "grok": 0.14,
            "claude-sonnet": 0.13,
            "deepseek": 0.12,
            "llama": 0.12            # 12% weight (lower accuracy)
        }

# Judge uses weights when synthesizing
weighted_consensus = sum(analyst.insight * weight for analyst, weight in zip(analysts, weights))
```

### 2. Specialist Roles
Assign each analyst a specialty:

- **GPT-4-Turbo**: Overall strategy
- **Claude Opus**: Risk analysis
- **Gemini**: Pattern detection
- **Grok**: Anomaly detection
- **DeepSeek**: Chain-of-thought on complex issues

### 3. Debate Mode
Let analysts respond to each other:

```
Round 1: All analysts analyze
Round 2: Judge highlights disagreements
Round 3: Analysts respond to disagreements
Round 4: Judge synthesizes final consensus
```

### 4. Confidence Intervals
Analysts provide confidence on each claim:

```json
{"claim": "WR will improve 3-5%", "confidence": 0.75, "evidence": "..."}
```

Judge aggregates confidence across analysts.

### 5. Self-Improvement Loop
- Track which analysts' insights proved correct (backtesting)
- Retrain prompts based on what worked
- Automatically adjust weights
- Generate new specialist prompts

---

## Monitoring & Safeguards

### 1. Claim Verification Dashboard
```
ANALYST ACCURACY (Last 30 Days)
  GPT-4-Turbo:     98.2% (242/247 claims verified)
  Claude Opus:     97.8% (238/243)
  Gemini:          96.1% (231/240)
  Grok:            95.4% (229/240)
  Claude Sonnet:   94.7% (227/240)
  DeepSeek:        93.2% (224/240)
  Llama:           91.8% (220/240)
```

### 2. Hallucination Alerts
```
ðŸš¨ HALLUCINATION DETECTED
  Analyst: llama-3-70b
  Claim: "Runner WR was 92%"
  Expected: 0.87 (from metrics)
  Stated: 0.92
  Action: Analyst output rejected
```

### 3. Judge Quality Metrics
- **Consensus accuracy**: Do judge's recommendations match outcomes?
- **Diversity**: Does judge surface all unique insights?
- **Clarity**: Is final report understandable?

### 4. Cost Tracking
```
DAILY COUNCIL COST
  Analysts: 7 calls Ã— $0.03 = $0.21
  Judge: 1 call Ã— $0.15 = $0.15
  Total: $0.36/day

  Monthly: $10.80
  Yearly: $131.40
```

---

## Recommended Implementation Path

### Phase 1: Basic Council (Week 1)
- 3 analysts: GPT-4-Turbo, Claude Opus, Gemini
- Claude Opus judge
- Number verification
- Daily summaries

### Phase 2: Full Council (Week 2)
- Add remaining 4 analysts
- Parallel execution
- Accuracy tracking

### Phase 3: Adaptive (Week 3)
- Dynamic weighting
- Specialist roles
- Confidence intervals

### Phase 4: Self-Improving (Week 4)
- Backtest predictions
- Prompt evolution
- Automated tuning

---

## Cost-Benefit Analysis

### Costs
- **Financial**: ~$0.36/day ($130/year)
- **Latency**: ~5-10s per summary (acceptable for daily)
- **Complexity**: 8 models to manage vs 1

### Benefits
- **Zero hallucination**: Multiple verification layers
- **Robust**: If one model fails, 6 others + judge remain
- **Diverse insights**: 7 perspectives > 1
- **Verifiable**: Every claim traceable
- **Adaptive**: Learns which models work best

**Verdict**: Strong ROI for critical decision-making system like Huracan

---

## Conclusion

The AI Council architecture provides:
1. âœ… **Zero hallucination** (layered verification)
2. âœ… **Diverse reasoning** (7 models)
3. âœ… **Self-correcting** (judge catches errors)
4. âœ… **Traceable** (verify links for all claims)
5. âœ… **Adaptive** (learns over time)

This is production-ready for Huracan's observability system.
