# üöÄ Brain Library - Next Steps Action Plan

## Overview

This document provides a clear, actionable plan for deploying and using the Brain Library ML enhancement system in production.

## ‚úÖ Prerequisites Check

### 1. Database Setup
- [ ] PostgreSQL database is running
- [ ] Database DSN is configured in `config/base.yaml` or environment variable
- [ ] Database user has CREATE TABLE permissions
- [ ] Connection can be tested

### 2. Dependencies
- [ ] All Python dependencies installed
- [ ] Database connection pool working
- [ ] Optional: TensorFlow installed (for LSTM)
- [ ] Optional: SHAP installed (for feature importance)
- [ ] Optional: sklearn installed (for permutation importance)

## üìã Step-by-Step Deployment

### Step 1: Configure Database Connection

**Option A: Environment Variable**
```bash
export DATABASE_DSN="postgresql://user:password@localhost:5432/huracan"
```

**Option B: Configuration File**
Edit `config/base.yaml`:
```yaml
postgres:
  dsn: "postgresql://user:password@localhost:5432/huracan"
```

**Verify Connection:**
```bash
python scripts/verify_brain_library_integration.py
```

### Step 2: Test Brain Library Integration

Run the verification script:
```bash
python scripts/verify_brain_library_integration.py
```

Expected output:
- ‚úÖ All imports successful
- ‚úÖ Brain Library initialized
- ‚úÖ Database schema created
- ‚úÖ All services available

### Step 3: Run Engine Training with Brain Library

Run Engine training (Brain Library integrates automatically):
```bash
python -m src.cloud.training.pipelines.daily_retrain
```

**What to expect:**
- Brain Library initializes automatically
- Feature importance is analyzed after training
- Model metrics are stored in Brain Library
- Model versions are tracked
- Automatic rollback if performance degrades

**Check logs for:**
```
brain_library_initialized
brain_integration_complete
feature_importance_analyzed
model_version_registered
```

### Step 4: Verify Data Storage

Check that data is being stored in Brain Library:

```python
from src.cloud.training.brain.brain_library import BrainLibrary

brain = BrainLibrary(dsn=dsn)

# Check feature importance
top_features = brain.get_top_features("BTC/USDT", top_n=20)
print(f"Top features: {top_features}")

# Check model metrics
metrics = brain.get_model_metrics("model_id", "BTC/USDT")
print(f"Model metrics: {metrics}")

# Check best model
best_model = brain.get_best_model("BTC/USDT")
print(f"Best model: {best_model}")
```

### Step 5: Monitor Brain Library Operations

**Check logs:**
```bash
grep "brain_library" logs/*.log
grep "feature_importance" logs/*.log
grep "model_versioning" logs/*.log
```

**Check database:**
```sql
-- Check feature importance
SELECT * FROM feature_importance ORDER BY analysis_date DESC LIMIT 10;

-- Check model metrics
SELECT * FROM model_metrics ORDER BY evaluation_date DESC LIMIT 10;

-- Check model registry
SELECT * FROM model_registry WHERE is_active = TRUE;

-- Check data quality logs
SELECT * FROM data_quality_logs ORDER BY timestamp DESC LIMIT 10;
```

## üîß Configuration Options

### Enable/Disable Brain Library

Brain Library automatically enables if database DSN is available. To disable:

1. Remove database DSN from settings
2. Engine will continue without Brain Library (graceful degradation)

### Configure Feature Importance Methods

Edit `brain_integrated_training.py` to change methods:
```python
importance_results = self.feature_analyzer.analyze_feature_importance(
    symbol=symbol,
    model=model,
    X=X_train,
    y=y_train,
    feature_names=feature_names,
    methods=['shap', 'permutation'],  # Change methods here
)
```

### Configure Rollback Threshold

Edit `model_versioning.py` to change rollback threshold:
```python
rollback_occurred = self.model_versioning.check_and_rollback(
    model_id=model_id,
    symbol=symbol,
    new_metrics=metrics,
    rollback_threshold=0.05,  # Change threshold (default: 5%)
)
```

## üìä Usage Examples

### Get Top Features for a Symbol

```python
from src.cloud.training.brain.brain_library import BrainLibrary

brain = BrainLibrary(dsn=dsn)
top_features = brain.get_top_features("BTC/USDT", top_n=20)
print(top_features)
```

### Get Best Model for a Symbol

```python
from src.cloud.training.brain.brain_library import BrainLibrary

brain = BrainLibrary(dsn=dsn)
best_model = brain.get_best_model("BTC/USDT")
print(f"Best model: {best_model['model_type']}")
print(f"Composite score: {best_model['composite_score']}")
```

### Select Model by Volatility Regime

```python
from src.cloud.training.services.model_selector import ModelSelector

selector = ModelSelector(brain)
model = selector.select_model_for_symbol(
    symbol="BTC/USDT",
    volatility_regime="high",  # 'low', 'normal', 'high', 'extreme'
)
```

### Run Comprehensive Evaluation

```python
from src.cloud.training.services.comprehensive_evaluation import ComprehensiveEvaluation

evaluator = ComprehensiveEvaluation(brain)
metrics = evaluator.evaluate_model(
    predictions=predictions,
    actuals=actuals,
    returns=returns,
    trades=trades,
)

report = evaluator.generate_evaluation_report(metrics)
print(report)
```

### Use Standardized LSTM

```python
from src.cloud.training.models.standardized_lstm import StandardizedLSTM

lstm = StandardizedLSTM(
    input_dim=20,
    lstm_units=128,
    num_layers=2,
    dropout_rate=0.2,
    use_bidirectional=True,
)

result = lstm.fit(X_train, y_train, X_val, y_val, epochs=50)
predictions = lstm.predict(X_test)
attention_weights = lstm.get_attention_weights(X_test)
```

## üîç Monitoring and Maintenance

### Daily Checks

1. **Check Brain Library logs:**
   ```bash
   grep "brain_library" logs/*.log | tail -20
   ```

2. **Check data quality:**
   ```python
   from src.cloud.training.brain.brain_library import BrainLibrary
   
   brain = BrainLibrary(dsn=dsn)
   summary = brain.get_data_quality_summary(start_time, end_time)
   print(summary)
   ```

3. **Check model performance:**
   ```python
   metrics = brain.get_model_metrics("model_id", "BTC/USDT")
   print(metrics)
   ```

### Weekly Maintenance

1. **Review feature importance trends:**
   - Check if top features are changing
   - Identify feature shifts

2. **Review model performance:**
   - Check if models are improving
   - Review rollback events

3. **Review data quality:**
   - Check for data quality issues
   - Resolve any critical issues

### Monthly Maintenance

1. **Archive old data:**
   - Archive old model metrics
   - Archive old feature importance data

2. **Optimize database:**
   - Analyze table statistics
   - Optimize indexes

3. **Review system performance:**
   - Check query performance
   - Optimize slow queries

## üö® Troubleshooting

### Brain Library Not Initializing

**Symptoms:**
- Logs show "brain_library_initialization_failed"
- Engine continues without Brain Library

**Solutions:**
1. Check database DSN is correct
2. Test database connection manually
3. Check database user has CREATE TABLE permissions
4. Check database is running

### Feature Importance Analysis Fails

**Symptoms:**
- Logs show "feature_importance_analysis_failed"
- No feature importance stored

**Solutions:**
1. Install SHAP: `pip install shap`
2. Install sklearn: `pip install scikit-learn`
3. Check if model has `predict` method
4. Check if data is valid

### Model Versioning Issues

**Symptoms:**
- Models not being versioned
- Rollback not working

**Solutions:**
1. Check database connection
2. Check model ID format
3. Check rollback threshold
4. Review model metrics

### Database Performance Issues

**Symptoms:**
- Slow queries
- Connection pool exhaustion

**Solutions:**
1. Increase connection pool size
2. Optimize database indexes
3. Archive old data
4. Review query performance

## üìà Performance Optimization

### Database Optimization

1. **Create indexes:**
   ```sql
   CREATE INDEX idx_feature_importance_symbol_date 
   ON feature_importance(symbol, analysis_date DESC);
   
   CREATE INDEX idx_model_metrics_model_date 
   ON model_metrics(model_id, evaluation_date DESC);
   ```

2. **Archive old data:**
   ```sql
   -- Archive data older than 1 year
   DELETE FROM model_metrics 
   WHERE evaluation_date < NOW() - INTERVAL '1 year';
   ```

### Feature Importance Optimization

1. **Use sampling for large datasets:**
   ```python
   # Sample data for SHAP analysis
   X_sample = X[:1000]  # Use first 1000 samples
   ```

2. **Use faster methods for large feature sets:**
   ```python
   methods=['correlation']  # Faster than SHAP for large feature sets
   ```

## üéØ Integration with Existing Workflows

### Engine Training Workflow

Brain Library is automatically integrated. No changes needed to existing workflow.

### Mechanic Integration (Future)

When Mechanic is built, add to nightly workflow:
```python
from src.cloud.training.pipelines.nightly_feature_workflow import run_nightly_feature_analysis

# Run after Engine training
results = run_nightly_feature_analysis(settings, symbols=["BTC/USDT", "ETH/USDT"])
```

### Hamilton Integration (Future)

When Hamilton is built, add to execution workflow:
```python
from src.cloud.training.services.model_selector import ModelSelector

selector = ModelSelector(brain)
model = selector.select_model_for_symbol("BTC/USDT", volatility_regime="high")
```

## üìù Checklist

### Initial Setup
- [ ] Database configured
- [ ] Database connection tested
- [ ] Brain Library verification passed
- [ ] Engine training tested with Brain Library
- [ ] Data storage verified

### Production Deployment
- [ ] Database optimized
- [ ] Indexes created
- [ ] Monitoring configured
- [ ] Logging configured
- [ ] Alerts configured

### Ongoing Maintenance
- [ ] Daily checks scheduled
- [ ] Weekly reviews scheduled
- [ ] Monthly maintenance scheduled
- [ ] Performance monitoring active
- [ ] Backup strategy in place

## üéâ Success Criteria

### Brain Library is working correctly if:
- ‚úÖ Database schema created successfully
- ‚úÖ Feature importance analyzed after training
- ‚úÖ Model metrics stored in Brain Library
- ‚úÖ Model versions tracked
- ‚úÖ Automatic rollback working
- ‚úÖ Top features retrievable
- ‚úÖ Best model selectable

### System is production-ready if:
- ‚úÖ All tests passing
- ‚úÖ Database optimized
- ‚úÖ Monitoring active
- ‚úÖ Logging configured
- ‚úÖ Alerts configured
- ‚úÖ Backup strategy in place
- ‚úÖ Documentation complete

## üöÄ Quick Start Commands

```bash
# 1. Verify installation
python scripts/verify_brain_library_integration.py

# 2. Test Brain Library
python scripts/test_brain_library_integration.py

# 3. Run demo
python scripts/demo_brain_library.py

# 4. Run Engine training (Brain Library integrates automatically)
python -m src.cloud.training.pipelines.daily_retrain

# 5. Check logs
grep "brain_library" logs/*.log
```

## üìö Additional Resources

- **Usage Guide**: `docs/BRAIN_LIBRARY_USAGE_GUIDE.md`
- **Architecture**: `HURACAN_ML_ENHANCEMENTS.md`
- **Integration**: `INTEGRATION_COMPLETE.md`
- **Quick Start**: `QUICK_START.md`

## üéØ Next Actions

1. **Immediate:**
   - Configure database DSN
   - Run verification script
   - Test Engine training with Brain Library

2. **Short-term:**
   - Monitor Brain Library operations
   - Review feature importance trends
   - Optimize database performance

3. **Long-term:**
   - Integrate with Mechanic (when built)
   - Integrate with Hamilton (when built)
   - Implement exchange API integration
   - Implement sentiment API integration

---

**Status**: ‚úÖ **READY FOR PRODUCTION**

**Last Updated**: 2025-01-08

